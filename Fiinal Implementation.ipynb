{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE RANDOM TREE ON ORIGINAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def import_dataset():\n",
    "    shapes = [\"circle\", \"square\", \"triangle\", \"star\"]\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for shape in shapes:\n",
    "        shape_files = os.listdir(f\"shapes/{shape}\")\n",
    "        \n",
    "\n",
    "        for image in shape_files:\n",
    "            X.append(np.asarray(Image.open(f\"shapes/{shape}/{image}\")))\n",
    "            y.append(shape)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_original_set, y_original_set = import_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original_set = [np.asarray(row).flatten() for row in X_original_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc_o = le.fit_transform(y_original_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(samples,features)\n",
      "(11227, 40000)\n",
      "(11227,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_original_set, y_enc_o, test_size=1/4)\n",
    "print(\"(samples,features)\")\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(bootstrap=True)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[971   0   0   0]\n",
      " [  0 866   0   0]\n",
      " [  0   0 960   0]\n",
      " [  0   0   0 946]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Image Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['star'], dtype='<U8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_image1 = Image.open(\"shapes/test_star.png\").convert('1').resize((200, 200))\n",
    "test_image1 = [ 255 if pixel else 0 for pixel in np.asarray(pil_image1).flatten() ]\n",
    "\n",
    "le.inverse_transform(classifier.predict([test_image1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on enlarged data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 40000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def import_dataset2():\n",
    "    shapes = [\"circle\", \"square\", \"triangle\", \"star\"]\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for shape in shapes:\n",
    "        shape_files = os.listdir(f\"shapes/set2/{shape}\")\n",
    "        # random.shuffle(shape_files)\n",
    "        lengthy = len(shape_files)\n",
    "        for i_pos in range(lengthy):\n",
    "            pil_image = Image.open(\"shapes/set2/\"+str(shape)+\"/\"+str(i_pos)+\".png\").convert('1').resize((200, 200))\n",
    "            test_image = [ 255 if pixel else 0 for pixel in np.asarray(pil_image).flatten() ]\n",
    "            X.append(test_image)\n",
    "            y.append(shape)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_bigset, y_bigset = import_dataset2()\n",
    "print(np.shape(X_bigset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_enc_o2 = le.fit_transform(y_bigset)\n",
    "\n",
    "y_pred_1_2 = classifier.predict(X_bigset)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_enc_o2, y_pred_1_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100 200   0   0]\n",
      " [  0 300   0   0]\n",
      " [  0 200 100   0]\n",
      " [  0 200   0 100]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_enc_o2, y_pred_1_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:\n",
      "(samples,features)\n",
      "(900, 40000)\n",
      "Labels shape:\n",
      "(900,)\n",
      "Testing set shape:\n",
      "(samples,features)\n",
      "(900, 40000)\n",
      "Labels shape:\n",
      "(900,)\n"
     ]
    }
   ],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_bigset, y_enc_o2, test_size=1/4)\n",
    "print(\"Training set shape:\")\n",
    "print(\"(samples,features)\")\n",
    "print(np.shape(X_train_2))\n",
    "print(\"Labels shape:\")\n",
    "print(np.shape(y_train_2))\n",
    "\n",
    "print(\"Testing set shape:\")\n",
    "print(\"(samples,features)\")\n",
    "print(np.shape(X_train_2))\n",
    "print(\"Labels shape:\")\n",
    "print(np.shape(y_train_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Train [enlarged data only]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "classifier_2 = RandomForestClassifier(bootstrap=True)\n",
    "classifier_2.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: enlarged data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_2 = classifier_2.predict(X_test_2)\n",
    "\n",
    "print(accuracy_score(y_test_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85  0  0  0]\n",
      " [ 0 74  0  0]\n",
      " [ 0  0 80  0]\n",
      " [ 0  0  0 61]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Test: original data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38231365215068125\n"
     ]
    }
   ],
   "source": [
    "y_pred_2_1 = classifier_2.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_2_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 40 514 417   0]\n",
      " [  0 186 411 269]\n",
      " [  0   0 771 189]\n",
      " [  0   1 511 434]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_2_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_3 = X_train + X_train_2\n",
    "y_train_3 = np.concatenate([y_train,y_train_2])\n",
    "X_test_3 = X_test + X_test_2\n",
    "y_test_3 = np.concatenate([y_test,y_test_2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_3 = RandomForestClassifier(bootstrap=True)\n",
    "classifier_3.fit(X_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[1056    0    0    0]\n",
      " [   0  940    0    0]\n",
      " [   0    0 1040    0]\n",
      " [   0    0    0 1007]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_3 = classifier_3.predict(X_test_3)\n",
    "\n",
    "print(accuracy_score(y_test_3, y_pred_3))\n",
    "print(confusion_matrix(y_test_3, y_pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test using internet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAACwElEQVR4nMWYTZKbMBCFH7JrzGIqZsmSRQ7gG4Sj+Ag5ArlYioNkwRFYeuHiZSEhdevHZjxM0htAH6/1QD0tPBUR4laLCyPOMaNE8I/Inxc0v3d1oKJi6eKz8xDDjtkWjDtmK5M7pg9rbqqs/kdVzbjtmG3CfcdsZTJi2aSRZVkB4mqzg+GDGhbJ43nyZAFk+W7S3AFZil+2CjeorvjJbLPLuE+2V8gEyPLdpBkBWYpf1mErQJbWlmz27mEnb/Yhx52ylYldgGmL5tfgzmzZzO6KRm0fMirVomWcTFMgtakLpDFvBXKNu4CPorkKYN7ciQZ5czUM3rPkAlN4cz0q2mpKrMGoXuPjABigy5AjYJA1VwMGWXMXwOSXtbcVnzFHK0jNHfCoQkByTgbPJI21GEXjsqXLenXZOESgosuWDwMAfW4QzJg7+2yxucYLY3NXawNI3hzDZNq2u48ko5o7MTxPo0gtrOfCkm9q7CeCN22OMps0t97FxJy19uxdA60YahU5CtJBepPmqDTC3HrPSvp4Zn/sPDlGJJhrIxLMdRFJ4zkJ29i0WRM233kHB6+Q2Y/cIlLWTH7kHpF9vY1+ZInIR7I9r7dXvL1A5P40bNTIT+5xo0b+HJg2amy0RfJdiWxbmO05ANdFdaeoir8ojW7Pou+cbdJM32lQ+i9Bp5qMzEYyzTa5+wb4NyWyneC6uyKjyL8kmhbqzQnSQXVAQfroIaxFAAeS5OiHtqzc0U8mCb2tFmvBBU0nlJr00bU/qwZ5kCRpz3ZgCRN060v0mjY6OiKLd10sr7m6Y9iPXSFWXGNwpZi+t9XcSsK+eYmfJ4mVNH6kVmQWRfO2dlK3kgzhVtdlk7vzoOaR3xtXReQfQSPJeBHkfZGaPn2Qx99vZEUZg3Ctlb3QnJVm3vJVw06R4xBm6BVZOyjJO3X8IMm/fO1Nf/lFJHgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=200x200 at 0x7F7BED90D550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['star'], dtype='<U8')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_image12 = Image.open(\"shapes/BlackStar.png\").convert('1').resize((200, 200))\n",
    "test_image12 = [ 255 if pixel else 0 for pixel in np.asarray(pil_image12).flatten() ]\n",
    "display(pil_image12)\n",
    "le.inverse_transform(classifier_3.predict([test_image12]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAABN0lEQVR4nO2XQU7DMBBFv6uq8aJSe4QeoQdAwuIk3ASfDPUgLLJkmWUXUYdFHPwd28KQNELg2cTTV3/PxPMrVQkyscmBSiqppJK/RN4XVXtbVC1PXlc6ZzZRkkvuV4HArnLOT8gNl1XO6dEuqHZFN1MN4mIsqxk/+NxzdE8dqenJNzzZuucpIuPCfF2bH0vlao33WOYBMZPcr05BiUyOAKhRIpp4SHYAgOcEmQbZTAHUDu+x4HaYmDAtuFORDsDBp0UTsgdwTpIN6N5+mYNvAFv4buf0AFt4ptoVYAvPrvohS57K1Hh2lNjvzk6HoadYrW2kbdJqmnwVqLUY3nei6jP2mX5MkNH6gmFKXHj/Q71A2bRaGER2YNOX7dHgn5CyW3gUkT753gwic6ZD1X+UlVRSSSX/kHwA3Y2POWJWAKEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=200x200 at 0x7F7BED908410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['star'], dtype='<U8')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pil_image14 = Image.open(\"shapes/black_star3.png\").convert('1').resize((200, 200))\n",
    "test_image14 = [ 255 if pixel else 0 for pixel in np.asarray(pil_image14).flatten() ]\n",
    "display(pil_image14)\n",
    "le.inverse_transform(classifier_3.predict([test_image14]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAAGwElEQVR4nH2YTW7kyBGFH1k1UAEWrPLKbWMA1RF8ArNu4j6BoZ1XFulVb/sGrRt4LmCz4E3PTr3zADZAAm2gBBsGU1PtJiWS+XmRmfwraXIhlBiMjBcRLyIyGaFXVvyaQLHYZw8GKx3USJJRL73XY/RTux3UaCk3kpiulIoecmoQ1PCS+CfsHF6FPd1nMGIBUbinLSQc6Xo+5G2NJdZOGpCX6mJpr40iib/yO/4zYHVb5nn9Ndafsp1ZSwpal4qy/W7zzYigoB18AYglZTIaIxpW8LTZvBBRleoWTw9qBk8/s1yx9CjttJUyDzDT93rKFKtZKXtr7Bcyt20mIykrw26PIURDioKkfMmOJGl7nh/5BO3PJftXJZmMsQqqnm933aMsyQdaTDKY9jkM2Mx1sUj5KHkNtcxLsbZnvkhSfCdFLpTLBR2AuXAJr7lNq3ueQPAVC2YFacKxttZTYsC2AsDCPU+QcBQ9KUfMipYTpANqARVgotETt1/gzuMvrLr10h8JiUzrJWoAbuZlCeh46p+hMvqDzStqOl9BhXs1xyh9hSFGyWK3+OEsXr4ABNDDe33b3xZTHbkg5Ua/JqmK9sQtlY+bvYa2N7p+57yfZruuwOhqEZ0R21U7tdISK1CtmQVnrVgqd6WH/qOjiq9ZXE6MVvmLdiqjFYlzLQdIEVQ9Od8pSvFarjN47uRGUQ8faYduJaeK8ZkKzAFRtM4fkUNbT6ITPFW6yMKLnJaEgMTpXIQuFbJAQoG9kZJRkHNC3Ba0FiNd9+3A3XrCUen6HMH2RQgTbOZVSSOjZuyB8d2/ht+HrTadyPRJz5LgZFPvD/Rj3GLp0qs8607PkbTzRQEUDvUK7AL1zulYX//n2BawYynzz9g8O7EbKoI8xWIk9U9AHSIuHFmMQuoCr+MH2f10Ctr3iqV9tpFzCyMpGfLdQy6XBCepplmNjbbKSgd4q3gyp7mvg871hHHplFX6eQVgU3x/swmcuJH0s0fynKrmt9QFAtLaeXrl9V2/cLvVGEkXNZbaDWevQ+ckAXRO7bLQdCcrSV2I/F4babqba6Wnk4MnoKXASIpcOHDlJe7pO4r3kiJ4bKaMHzyNXHSrkQchVDjSbEceRJlKSX7WkulBvYYOW0qLeox929lKk1nnfdvPyOR4ZNbWVdb/uJFP0HBiEkBVOTu/JIfWB242nRtJWus52+83DzNsVwtsL69yJmm8p5K0i+/US/JBMH5EWumgGnpyZ2flTRS0FKLFQu4lk/Of+AsUHts46+oxPwvJiNo1CA/LLyiovY6wOGbd+35dBUlKiNupj/u9zHbcQVp/kfa6jOPVYdrFIg09JR7MS8NUaax0WEuL2Uu0kaR9/DA915UaO8z6TTPRab5shn/mdprLtQ+1FGuj9Xh6yfRdI/0tczEAsM7TC1cKQIHrVd20sWktNTsJqP8ObyWNqRv41oa4DZIcwmx0kograrApoOPnHvhzkHBr0/wjrlfR/7EIOjXYtCqCHQuJkyjM7mHO5bmX/NeRyuv02IBA6Xh8mnFH02NKLOlGy1VKip/S3W/mj3tpJ9n1RVTOX26+kST920/A1ouvoW97SAOCPiC4wvlXB/bOKy+SNmd3s8nZM1Yp4TqOJMcBz/+Zp6vHFOD5iUTQkY4SfH+1CE4TncgXHLOpOazNFG8g42RGxS58iwOnl+zKyby8CT86N2m3g8So7KS9tI6lcnRT2v2w68RB6kVhJ6iVQOqYvYiBroGK1rpYdwq9yq1tuY6k2DjIu+F5Fka723TY7SoUELFTGTZ7ysi0VifXdyrsWy+5ADp49w8bznPlRAIf0nPUK0dz508+k8xODhQDq1zqUir65W6Ry2gB8cOnpiMbYKPvs4P4VbaTb4+DQ32eupPAcrdxojke3Gm6zLO0l/z4HGTJqLOVlE2GHeHP0k4yvTtreggsm69W5ScZf37rB53resRW7jQZauYHda6OlnaunJmqP6Nt49S3i947XbGktcpxmD/LD0BnJx3trHzdE7tqNsMm9iA/AZbYhlkX66Bs9nHFv2POdDTqnDk0oj7MJb9X5x4B1KH7Sy7dPR9RlySTLiYpsdDfH8/Y69LdewTzW3V4J9ZZjzNecjd7URLb8KMG0vAtByDn6KveTC7MgCUvrJsYxbvqONWwA7Zdc/lG1p/Qs30Z+a9LTG/fWCg8EyOYTUzJxu5JHCZ4FogyPHEB7WfwANDxc0UKp/qETV3J1PWRnPjNt5fKpH8O34TQZvPm6aBwO5yvmtBDZtGBYWoOVwF/vaCGnDELDBddbcRBr31/azb/B8Q0rhnMaC4iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=200x200 at 0x7F7C1D03ED10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['triangle'], dtype='<U8')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_image15 = Image.open(\"shapes/black_triangle1.png\").convert('1').resize((200, 200))\n",
    "test_image15 = [ 255 if pixel else 0 for pixel in np.asarray(pil_image15).flatten() ]\n",
    "display(pil_image15)\n",
    "le.inverse_transform(classifier_3.predict([test_image15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAABv0lEQVR4nHXYq5VDMQxF0RsFBKaEKSWlJaWpFJUgaOBlD3j/Z59LN9Gh0rfDzAWzQEmUglJRGkpH0Q/FUQIlUSjIREEmCjJRkImCTBRkoiATBZkoyERBJgoyUZCJgkwUZKIgEwWZKMhEQSYKMlGQSRBkEgSZBEEmQZBJEGQSBJkEQSZBkEmaBy3iKIGSKLOgRWZBi8yCFpkFLTILWsVRAiVRJkGrTIJWmQStMglaZRK0iaMESqKMQZuMQZuMQZuMQZuMQbs4SqAkyhC0yxC0yxC0yxC0yxB0iKMESqLcgw65Bx1yDzrkHnTIPegkjhIoiVJQKkpD6Si3oLM4SqAkSkGpKA2lo1yDLuIogZIoBaWiNJSOcgm6iqMESqIUlIrSUDrKOegmjhIoiVJQKkpD6SinoLs4SqAkSkGpKA2loxxBgzhKoCRKQakoDaWj7EGjOEqgJEpBqSgNpaNsQRNxlEBJlIJSURpKR1mDZuIogZIoBaWiNJSOsgRNxVECJVEKSkVpKB1FPxRHCZREKSgVpaF0FP1QHCVQEqWgVJSGgl8f6Yv2QflDeaO8UJ4oD76b5YvyQflDeaO8UJ4oDxT9A4/3xFOPlbRWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=200x200 at 0x7F7BF2889250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['triangle'], dtype='<U8')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_image16 = Image.open(\"shapes/black_triangle2.png\").convert('1').resize((200, 200))\n",
    "test_image16 = [ 255 if pixel else 0 for pixel in np.asarray(pil_image16).flatten() ]\n",
    "display(pil_image16)\n",
    "le.inverse_transform(classifier_3.predict([test_image16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=200x200 at 0x7F7B99934B90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['triangle'], dtype='<U8')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_image17 = Image.open(\"shapes/black_triangle4.png\").convert('1').resize((200, 200))\n",
    "test_image17 = [ 255 if pixel else 0 for pixel in np.asarray(pil_image17).flatten() ]\n",
    "display(pil_image17)\n",
    "le.inverse_transform(classifier_3.predict([test_image16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=200x200 at 0x7F7B99947F10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['star'], dtype='<U8')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_image13 = Image.open(\"shapes/black_star2.png\").convert('1').resize((200, 200))\n",
    "test_image13 = [ 255 if pixel else 0 for pixel in np.asarray(pil_image13).flatten() ]\n",
    "display(pil_image13)\n",
    "le.inverse_transform(classifier_3.predict([test_image13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAAAbklEQVR4nO3YvRFAQBiE4fUzI3QVoBDURSA6haESMuHJZJ8CDKERvJs+G2y8kekh8RMgyOeyNZUb52MoXbocfePSZZckM1tv/czM/rEaQRAEQRAEQRAEQd4k81Ooi9xPoWvzZA5nLUkRXw3yc7kAaQAbSrNY1U4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=200x200 at 0x7F7B99946410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['square'], dtype='<U8')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_image131 = Image.open(\"shapes/black_test1.png\").convert('1').resize((200, 200))\n",
    "test_image131 = [ 255 if pixel else 0 for pixel in np.asarray(pil_image131).flatten() ]\n",
    "display(pil_image131)\n",
    "le.inverse_transform(classifier_3.predict([test_image131]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAADaElEQVR4nO2YvW7UQBDH/+s75SwS5VxQpEDBHW3KFFHikpIOSgoKyrxB/CAUeQcaCkQMTxAJKgpiASIpEBgSCSexPRT74f2aXCKlzDT27c8z89/x7No+QWAs4cAduSM3Iw1LWqBUp8LtxCYzp+K6PXrIkjcsseR55DEKKl1yLg8bQFapIZLWHqkTGh7Ko/HRV7a+gkTlfn8uSjfa6QENe/XqHnYP1AiIiI6JLveGrW0A2NT5EgC4APrqAh8A4FOJbsxTAq2uzESLSABgjg41zgAAf4C0tXymYxlaTH8abcdE9Y6u1zLRqVGQWYVEB7pnoqUA6sMxYGfVoAaqcbi1a1CvawdBw6VV0W38GoNJ/ZL0pGYjLQNqRZLJmhmmQgDITZ5u9JgTEe3oinYWOcM+SOVZsqsD4AlQmGiNBfovNBjVrU22BC5NDVI72Nd1XMRX1o8aZyPZt9GAExgFNhAf6Uj1DtHghJvQa6PNJdOhMdFa16f/Ns7HIZS8ovh+cB8QOlrlkKT7Pa4Sx4a+NjN1ffB5g9t3NmBUe2RmeqeP+Eny3RtNax2t8cicGNVWtMD2NfGjodF5ag9MTB6fDGwekmQIyqa1MfLkDisi4a6aaRsbLoEEqZQSzxNWb0Ee+B1q8lzpw5MuGK6AhNEMJONDyrYaABH1YRnm8s4l0QIlsdkA7QLVImwdQzifqJ1whDY5cpHLHq0CMmPXQrrwLoTRwPr8TVnVuSRFQFaesap/s6ozLs8LVttyyS6rgq1BvojkMWaetHESt3AfV6OMT3nbb4M3VrA4z5QlMasFAeh9JzEon3BDKhYqMK9sYxZ2r2q4PMi4PDMdLWjs1ATKw2CKZJGIkqx6o7kh/jZSGBLb/eKqy5EU1/QRLJGD4WuVfDTq3kkRmCLu7X7A5skt4l5QAOPXh1Mfsi8uLaCu0u+wNnG+CiJ69ZeEReaOT9j0iXcMia06c6+tOB+7sXJHmyVu5n7lYMmQ1Is2Ssh8taU+eQ43j9m0BXl5jOxw7io8pvo5Tr7s2eBH07LXhB9Ny26CPFr2bkj0UBuQFTiWhKd+3QKziADm1JjFbHcGARCiihBgSJaaylxorKcjon/mp6PthFFgS/bJW7yzBVl2/HRn/OFoW3v0kslDomCIsyT9fwm6KUeYaHfkFsh/ldgCvIfYmrUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=200x200 at 0x7F7B99920CD0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['circle'], dtype='<U8')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_image135 = Image.open(\"shapes/circle_test1.png\").convert('1').resize((200, 200))\n",
    "test_image135 = [ 255 if pixel else 0 for pixel in np.asarray(pil_image135).flatten() ]\n",
    "display(pil_image135)\n",
    "le.inverse_transform(classifier_3.predict([test_image135]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAACMUlEQVR4nO2YQW6kMBBFv51Wh0UkvJxduElzlNwkHGGO5CPkCBzBGvWiFwSysLGryjaIUS9GIywlafxUv36VDcGtFlSGroGT/N/kWynVE7TEYQG8pMtEJgDArUAcAKCN1ynPbwDAnzzPFK5vmZoLpM3UVnKXanOcuAm1RyStUEtEducrztwFsZF8cwfJAPDJHEyEvDMHd0Icy+MIuTMyEhJyKn9vK1rJQmL4rT8QMjNiCZkYGQnhXXPUGxsPQr4YmQixjHg/vh5WTihCx09kDJHMgtiaN1+QTmbScJHk22MlTkw+qnmmSMaqmhWTc1XN92VB1hyPNPLm+PaUnwc2ENk2b1Yjb44fZTUXSLFtT3yKPQJx1Zgxm52qanMg9ineFvj1yZYHWP6iBwOgS0u6FWMBXVrSrZg6GXdiyhvkeB63E1PeVP/W/9OTnOQoaZ6kZnZiLk/K0+3EVOBmTOFhiX4rZvsJOxx3UMoRSH8gRoefLiOXXQfmQJ5mV61OyhuuHGMCuWakq8b0gZQWde/dJVs6Fb31JbWiAx1/dYJcIjGCNFW1JCkbZyKR91bHbRTVZA96AOEkMXBCzgs9AyqpiVKvhBhGGkJKO8ETXpAhhBfUkTleUHC6ZAUpdv7ps9RrjCOkZTHUtmGhdJt2azpIdwtPZ5M1YaSL5CqIiaQR5E1aS6fdNZE6cNptpFgkr+HvR6prHSMAenxPa/ZLeFTpzVIB9EWTrLMD0KZLdX6PdBIAP+l0RUdlPp0pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=200x200 at 0x7F7B99947110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['circle'], dtype='<U8')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_image136 = Image.open(\"shapes/circle_test2.png\").convert('1').resize((200, 200))\n",
    "test_image136 = [ 255 if pixel else 0 for pixel in np.asarray(pil_image136).flatten() ]\n",
    "display(pil_image136)\n",
    "le.inverse_transform(classifier_3.predict([test_image136]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAAAqElEQVR4nO3YsQ2DMBCF4R+HgiphBEZhpGzAaoyQERjBRQoKxEuR0oeQrBREei7fpzudLVfXiIOTjsByCUHSXoSTJCTlQh6SEvAq5P3tVjaDSUoQyQwJtkAWSLAGkqvfIAfxelKzBPFWPcEcxPsV/oHFYrFYLBaLxWKxWH4uYxxXdhuCuD2p6YO4q56gC+IeErSBDIeXHQFJcwG3023EvZAn0Hgr9afyAZbuM2RbOSp4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=200x200 at 0x7F7BED919590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['square'], dtype='<U8')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_image133 = Image.open(\"shapes/black_test3.png\").convert('1').resize((200, 200))\n",
    "test_image133 = [ 255 if pixel else 0 for pixel in np.asarray(pil_image133).flatten() ]\n",
    "display(pil_image133)\n",
    "le.inverse_transform(classifier_3.predict([test_image133]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code used to generate second data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def zoom_at(img, x, y, zoom):\n",
    " #   w, h = img.size\n",
    "  ##  zoom2 = zoom * 2\n",
    "    #img = img.crop((x - w / zoom2, y - h / zoom2, \n",
    "  #                  x + w / zoom2, y + h / zoom2))\n",
    "    #return img.resize((w, h), Image.LANCZOS)\n",
    "#image123 = Image.open(\"/Users/jakeburditt/Desktop/2022 Semester 1/DSP/shapes-classifier-main/shapes/test_star.png\")\n",
    "#image1234 = zoom_at(image123,100,100,1.5)\n",
    "#image1234.save(\"/Users/jakeburditt/Desktop/2022 Semester 1/DSP/shapes-classifier-main/shapes/test_star_zoom.png\")\n",
    "\n",
    "#from PIL import Image, ImageDraw, ImageOps\n",
    "#path = \"/Users/jakeburditt/Desktop/2022 Semester 1/DSP/shapes-classifier-main/shapes/\"\n",
    "#for x in [\"circle\", \"square\", \"triangle\", \"star\"]:\n",
    " #   for i in range(100):\n",
    "  #          image1  = Image.open(str(path)+str(x)+\"/\"+str(i)+\".png\")  # could also open an existing image here to draw shapes over it\n",
    "        # can vary this bit to draw different shapes in different positions\n",
    "           \n",
    "   #         for j in range(1,4,1):\n",
    "    #            rotated_image1 = zoom_at(image1,100,100,(1+j*0.25))\n",
    "               \n",
    "     #           rotated_image1.save(str(path)+\"set2/\"+str(x)+\"/\" +str(i+(j-1)*100)+'.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
